{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txCP1_fZR1PW"
      },
      "source": [
        "# Pytorch\n",
        "\n",
        "Pytorch는 TensorFlow와 함께 Deep Learning에서 가장 널리 사용되는 framework입니다.\n",
        "\n",
        "초기에는 Torch라는 이름으로 Lua 언어 기반으로 만들어졌으나, 이후 python 기반으로 변경한 것이 Pytorch입니다.\n",
        "\n",
        "New York 대학교와 Facebook이 공동으로 만들었고, Deep Learning 연구자들 사이에서는 가장 대중적으로 널리 사용되는 framework입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Q803K53JFb"
      },
      "source": [
        "## Pytorch Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXbSk7vvWlxn"
      },
      "source": [
        "### Pytorch import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J0WMNj3QxxT"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yYFv2sHXRyO"
      },
      "source": [
        "### Pytorch 맛보기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_5pN_jhToDL"
      },
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RdlFXVPXh7V"
      },
      "source": [
        "## MNIST Data down 받기\n",
        "\n",
        "# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTY_cIF1XpJd"
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "# 데이터로더를 생성합니다.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B31uL7ycX1re"
      },
      "source": [
        "# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsrTn40qX2KV"
      },
      "source": [
        "# Loss 함수와 Optimizer 설정\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36iRc41kYFj1"
      },
      "source": [
        "# Training을 위한 함수\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 예측 오류 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6_3yNPMYKO2"
      },
      "source": [
        "# Test를 위한 함수\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnhgYl0yYZJX"
      },
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6cUrmf0Z4fo"
      },
      "source": [
        "내가 쓴 손글씨로 Test 해봅시다.\n",
        "\n",
        "Colab을 쓰는 경우에는 아래 cell을 실행하면 파일을 업로드할 수 있습니다.\n",
        "\n",
        "그림판과 같은 도구를 이용하여 손으로 숫자를 쓴 다음 파일로 저장하고 업로드 합니다.\n",
        "\n",
        "이 때 파일명은 image.png로 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59W62-QgYwMO"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0X9zCSmaMCG"
      },
      "source": [
        "# image file의 경로 설정\n",
        "cur_dir = os.getcwd()\n",
        "img_path = os.path.join(cur_dir, 'image.png')\n",
        "# image file 읽기\n",
        "cur_img = Image.open(img_path)\n",
        "# 28x28로 resize\n",
        "cur_img = cur_img.resize((28, 28))\n",
        "image = np.asarray(cur_img)\n",
        "\n",
        "# color image일 경우 RGB 평균값으로 gray scale로 변경\n",
        "try:\n",
        "  image = np.mean(image, axis=2)\n",
        "except:\n",
        "  pass\n",
        "# upload한 image는 흰 배경에 검은 글씨로 되어 있으므로, MNIST data와 같이 검은 배경에 흰 글씨로 변경\n",
        "image = np.abs(255-image)\n",
        "# MNIST와 동일하게 data preprocessing(255로 나눠줌)\n",
        "image = image.astype(np.float32)/255.\n",
        "# 화면에 출력하여 확인\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzj2yru_aW_C"
      },
      "source": [
        "image = torch.as_tensor(image).to(device).reshape(1,1,28,28)\n",
        "model.eval()\n",
        "predict = model(image)\n",
        "print(\"Model이 예측한 값은 {} 입니다.\".format(predict.argmax(1).item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJBl5rK132CD"
      },
      "source": [
        "### FasionMNIST data 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH1pEvzUGv-7"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq87kH2t2_8W"
      },
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcBC4NAm3_Rr"
      },
      "source": [
        "### 데이터 시각화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4sJcQTr36nv"
      },
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNeINRxdHYb7"
      },
      "source": [
        "### DataLoader 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOiMGBbgGpwb"
      },
      "source": [
        "# DataLoader 만들기\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDlvthoZGpzU"
      },
      "source": [
        "# DataLoader를 통해 반복하기(iterate)\n",
        "# 이미지와 정답(label)을 표시합니다.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3LsVobUHass"
      },
      "source": [
        "### Custom Dataset, Data Loader 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZHsPRBc4Ddn"
      },
      "source": [
        "# 간단한 Custom Dataset/Transform/DataLoader 만들기\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, np_data, transform=None):\n",
        "    self.data = np_data\n",
        "    self.transform = transform\n",
        "    self.len = np_data.shape[0]\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "  def __getitem__(self, idx):\n",
        "    sample = self.data[idx]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-0Eztv9GwSR"
      },
      "source": [
        "def square(sample):\n",
        "  return sample**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ahheTBjGJE3"
      },
      "source": [
        "trans = tr.Compose([square])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMGw6_wTDkP6"
      },
      "source": [
        "np_data = np.arange(10)\n",
        "\n",
        "custom_dataset = CustomDataset(np_data, transform=trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjfLJqfdD1CS"
      },
      "source": [
        "custom_dataloader = DataLoader(custom_dataset, batch_size=2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OijYYFTHD_Xy"
      },
      "source": [
        "for _ in range(3):\n",
        "  for data in custom_dataloader:\n",
        "    print(data)\n",
        "  print(\"=\"*20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBIhASxPHgDb"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1CP4rACEJxd"
      },
      "source": [
        "# device 설정\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVDCYr85H-5j"
      },
      "source": [
        "### Model class 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbtUxoUbH7Pe"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eXhySj6IJaW"
      },
      "source": [
        "# Model instance 생성, device 설정\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_k0QBI2INoW"
      },
      "source": [
        "# 가상의 data 만들어서 예측해보기\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsIY58t0JB0V"
      },
      "source": [
        "## Training / Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlkPl2JJJI9E"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LMgsDSoIYtG"
      },
      "source": [
        "# 손실 함수를 초기화합니다.\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlqtzkDJOZU"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7dELqElJNkW"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaYAnBUCJXe-"
      },
      "source": [
        "### Training / Validation(Test) Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tje2CPpeJR5W"
      },
      "source": [
        "# Training을 위한 함수\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # 예측(prediction)과 손실(loss) 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Test를 위한 함수\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTp_mTRKJxNe"
      },
      "source": [
        "# 학습 진행하기\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSAxLgwNMJke"
      },
      "source": [
        "## Model 저장하고 불러오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAE2aT-LMPja"
      },
      "source": [
        "#### parameter만 저장하고 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD_9zmzLJ5aP"
      },
      "source": [
        "# 학습된 model parameter 저장\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suOyvvDpMTeA"
      },
      "source": [
        "# 새 Model instance 생성, device 설정\n",
        "model2 = NeuralNetwork().to(device)\n",
        "print(model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtLNWzdMmP_"
      },
      "source": [
        "# test\n",
        "model2.eval()\n",
        "test_loop(test_dataloader, model2, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epmWcHXlMsj3"
      },
      "source": [
        "# 저장한 parameter 불러오기\n",
        "model2.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JBBYyaIM37v"
      },
      "source": [
        "# test\n",
        "model2.eval()\n",
        "test_loop(test_dataloader, model2, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjPKRMdtNFH_"
      },
      "source": [
        "### Model 전체를 저장하고 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_ZjA5ehM78H"
      },
      "source": [
        "# 저장하기\n",
        "torch.save(model, 'model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD0OjcyJNJ0_"
      },
      "source": [
        "# 불러오기\n",
        "model3 = torch.load('model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjZICUrCNM7X"
      },
      "source": [
        "# test\n",
        "model3.eval()\n",
        "test_loop(test_dataloader, model2, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2vRMsioNV3W"
      },
      "source": [
        "## Tensorboard 사용하여 시각화하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGnzohCJNR9Y"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BENziPMuNluP"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter('./logs/pytorch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVB7XWHwO9jH"
      },
      "source": [
        "# 새 Model instance 생성, device 설정\n",
        "model4 = NeuralNetwork().to(device)\n",
        "print(model4)\n",
        "\n",
        "model4.eval()\n",
        "test_loop(test_dataloader, model4, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiTetkobNwUX"
      },
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "writer.add_graph(model4, X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgGBmkZOONG4"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 예측(prediction)과 손실(loss) 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "        total_loss += loss / len(dataloader)\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8o9uvecOZZ_"
      },
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W2fyFMqPji4"
      },
      "source": [
        "parameters = ['Weight1', 'Bias1', 'Weight2', 'Bias2']\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    writer.add_scalar('training loss', train_loss, t)\n",
        "    for param, name in zip(model.parameters(), parameters):\n",
        "        writer.add_histogram(name, param, t)\n",
        "    test_loss = test(test_dataloader, model, loss_fn)\n",
        "    writer.add_scalar('test_loss', test_loss, t)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeHuGnvaQAaQ"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk6SdayOQDRg"
      },
      "source": [
        "%tensorboard --logdir './logs/pytorch'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbX3qNzrQP_g"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}